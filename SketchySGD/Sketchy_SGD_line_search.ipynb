{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b8943ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420dbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"stl10_final.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455fe943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27639</th>\n",
       "      <th>27640</th>\n",
       "      <th>27641</th>\n",
       "      <th>27642</th>\n",
       "      <th>27643</th>\n",
       "      <th>27644</th>\n",
       "      <th>27645</th>\n",
       "      <th>27646</th>\n",
       "      <th>27647</th>\n",
       "      <th>27648</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>143</td>\n",
       "      <td>110</td>\n",
       "      <td>146</td>\n",
       "      <td>143</td>\n",
       "      <td>110</td>\n",
       "      <td>146</td>\n",
       "      <td>143</td>\n",
       "      <td>110</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>138</td>\n",
       "      <td>127</td>\n",
       "      <td>119</td>\n",
       "      <td>147</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>138</td>\n",
       "      <td>128</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129</td>\n",
       "      <td>140</td>\n",
       "      <td>73</td>\n",
       "      <td>124</td>\n",
       "      <td>133</td>\n",
       "      <td>68</td>\n",
       "      <td>138</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>128</td>\n",
       "      <td>94</td>\n",
       "      <td>151</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "      <td>194</td>\n",
       "      <td>164</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>179</td>\n",
       "      <td>223</td>\n",
       "      <td>114</td>\n",
       "      <td>163</td>\n",
       "      <td>203</td>\n",
       "      <td>104</td>\n",
       "      <td>165</td>\n",
       "      <td>191</td>\n",
       "      <td>103</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>114</td>\n",
       "      <td>140</td>\n",
       "      <td>117</td>\n",
       "      <td>104</td>\n",
       "      <td>131</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "      <td>123</td>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>130</td>\n",
       "      <td>91</td>\n",
       "      <td>200</td>\n",
       "      <td>189</td>\n",
       "      <td>164</td>\n",
       "      <td>127</td>\n",
       "      <td>112</td>\n",
       "      <td>89</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>131</td>\n",
       "      <td>89</td>\n",
       "      <td>145</td>\n",
       "      <td>129</td>\n",
       "      <td>93</td>\n",
       "      <td>155</td>\n",
       "      <td>138</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27649 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    146    143    110    146    143    110    146    143    110    146  ...   \n",
       "1    129    140     73    124    133     68    138    144     84    144  ...   \n",
       "2    179    223    114    163    203    104    165    191    103     89  ...   \n",
       "3     14     18     29     16     21     35     14     21     41     12  ...   \n",
       "4    147    130     91    200    189    164    127    112     89     68  ...   \n",
       "\n",
       "   27639  27640  27641  27642  27643  27644  27645  27646  27647  27648  \n",
       "0    138    127    119    147    136    122    138    128     93      1  \n",
       "1    146    128     94    151    130     91    194    164    123      0  \n",
       "2    124    149    128    114    140    117    104    131    109      1  \n",
       "3    125     80     18    123     80     18    120     80     18      0  \n",
       "4    147    131     89    145    129     93    155    138    108      0  \n",
       "\n",
       "[5 rows x 27649 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c50c2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1].to_numpy()\n",
    "Y = df.iloc[:, -1].to_numpy()\n",
    "X = X / 256.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331bbd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Optimizer\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0394cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "997640a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainData(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_data = TrainData(torch.FloatTensor(X), torch.FloatTensor(Y))\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81586365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassification, self).__init__()\n",
    "        # Number of input features is 27648.\n",
    "        self.layer_1 = nn.Linear(27648, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.layer_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9209da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d41cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88dcc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_product(xs, ys):\n",
    "    \n",
    "    return sum([torch.sum(x * y) for (x, y) in zip(xs, ys)])\n",
    "\n",
    "def normalization(v):\n",
    "    # normalize a vector\n",
    "    \n",
    "    s = group_product(v, v)\n",
    "    s = s**0.5\n",
    "    s = s.cpu().item()\n",
    "    v = [vi / (s + 1e-6) for vi in v]\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff062e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NysHessianpartial():\n",
    "    \n",
    "    def __init__(self, rank, rho):\n",
    "        self.rank = rank\n",
    "        # rho is the regularization in Nystrom sketch\n",
    "        self.rho = rho\n",
    "    \n",
    "    def get_params_grad(self, model):\n",
    "        # get parameters and differentiation\n",
    "        params = []\n",
    "        grads = []\n",
    "        for param in model.parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            params.append(param)\n",
    "            grads.append(0. if param.grad is None else param.grad + 0.)\n",
    "        return params, grads\n",
    "    \n",
    "    def update_Hessian(self, X_batch, y_batch, model, criterion, device):\n",
    "        \n",
    "        shift = 0.001\n",
    "        # get the model parameters and gradients\n",
    "        params, gradsH = self.get_params_grad(model)\n",
    "        # remember the size for each group of parameters\n",
    "        self.size_vec = [p.size() for p in params]\n",
    "        # store random gaussian vector to a matrix\n",
    "        test_matrix = []\n",
    "        # Hessian vector product\n",
    "        hv_matrix = []\n",
    "        \n",
    "        for i in range(self.rank):\n",
    "            # generate gaussian random vector\n",
    "            v = [torch.randn(p.size()).to(device) for p in params]\n",
    "            # normalize\n",
    "            v = normalization(v)\n",
    "            # zero vector to store the shape\n",
    "            hv_add = [torch.zeros(p.size()).to(device) for p in params]\n",
    "        \n",
    "            # update hessian with a subsample batch\n",
    "            \n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            model.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch.unsqueeze(1))\n",
    "            loss.backward(create_graph=True)\n",
    "            params, gradsH = self.get_params_grad(model)\n",
    "            # calculate the Hessian vector product\n",
    "            hv = torch.autograd.grad(gradsH, params, grad_outputs=v,only_inputs=True,retain_graph=True)\n",
    "            # add initial shift\n",
    "            for i in range(len(hv)):\n",
    "                hv_add[i].data = hv[i].data.add_(hv_add[i].data)    \n",
    "                hv_add[i].data = hv_add[i].data.add_(v[i].data * torch.tensor(shift)) \n",
    "            \n",
    "            # reshape the Hessian vector product into a long vector\n",
    "            hv_ex = torch.cat([gi.view(-1) for gi in hv_add])\n",
    "            # reshape the random vector into a long vector\n",
    "            test_ex = torch.cat([gi.view(-1) for gi in v])\n",
    "            \n",
    "            # append long vectors into a large matrix\n",
    "            hv_matrix.append(hv_ex)\n",
    "            test_matrix.append(test_ex)\n",
    "        \n",
    "        # assemble the large matrix\n",
    "        hv_matrix_ex = torch.column_stack(hv_matrix)\n",
    "        test_matrix_ex = torch.column_stack(test_matrix)\n",
    "        # calculate Omega^T * A * Omega for Cholesky\n",
    "        choleskytarget = torch.mm(test_matrix_ex.t(), hv_matrix_ex)\n",
    "        # perform Cholesky, if fails, do eigendecomposition\n",
    "        # the new shift is the abs of smallest eigenvalue (negative) plus the original shift\n",
    "        try:\n",
    "            C_ex = torch.linalg.cholesky(choleskytarget)\n",
    "        except:\n",
    "            # eigendecomposition, eigenvalues and eigenvector matrix\n",
    "            eigs, eigvectors = torch.linalg.eigh(choleskytarget)\n",
    "            shift = shift + torch.abs(torch.min(eigs))\n",
    "            # add shift to eigenvalues\n",
    "            eigs = eigs + shift\n",
    "            # put back the matrix for Cholesky by eigenvector * eigenvalues after shift * eigenvector^T \n",
    "            C_ex = torch.linalg.cholesky(torch.mm(eigvectors, torch.mm(torch.diag(eigs), eigvectors.T)))\n",
    "        \n",
    "        # triangular solve\n",
    "        B_ex = torch.linalg.solve_triangular(C_ex, hv_matrix_ex, upper = False, left = False)\n",
    "        # SVD\n",
    "        U, S, V = torch.linalg.svd(B_ex, full_matrices = False)\n",
    "        self.U = U\n",
    "        self.S = torch.max(torch.square(S) - torch.tensor(shift), torch.tensor(0.0))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4200d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NysHessianOpt(Optimizer):\n",
    "    r\"\"\"Implements NysHessian.\n",
    "    Args:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float): learning rate\n",
    "        rank (int): sketch rank\n",
    "        rho: regularization\n",
    "    \"\"\"\n",
    "    def __init__(self, params, rank = 100, rho = 0.5):\n",
    "        # initialize the optimizer    \n",
    "        defaults = dict(rank = rank, rho = rho)\n",
    "        self.nysh = NysHessianpartial(rank, rho)\n",
    "        super(NysHessianOpt, self).__init__(params, defaults)\n",
    "         \n",
    "    def step(self, lr):\n",
    "        # one step update\n",
    "        for group in self.param_groups:\n",
    "            rho = group['rho']\n",
    "            # compute gradient as a long vector\n",
    "            g = torch.cat([p.grad.view(-1) for p in group['params']])\n",
    "            # calculate the search direction by Nystrom sketch and solve\n",
    "            UTg = torch.mv(self.nysh.U.t(), g) \n",
    "            g_new = torch.mv(self.nysh.U, (self.nysh.S + rho).reciprocal() * UTg) + g / rho - torch.mv(self.nysh.U, UTg) / rho            \n",
    "            ls = 0\n",
    "            # update model parameters\n",
    "            for p in group['params']:\n",
    "                gp = g_new[ls:ls+torch.numel(p)].view(p.shape)\n",
    "                ls += torch.numel(p)\n",
    "                p.data.add_(-lr * gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a515262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NysHessianOptlinesearch(Optimizer):\n",
    "\n",
    "    def __init__(self, params, rank = 100, rho = 0.5):\n",
    "        # initialize the optimizer    \n",
    "        defaults = dict(rank = rank, rho = rho)\n",
    "        self.nysh = NysHessianpartial(rank, rho)\n",
    "        super(NysHessianOptlinesearch, self).__init__(params, defaults)\n",
    "    \n",
    "    def compute_direction(self):\n",
    "        self.directions = []\n",
    "        self.inner_product = []\n",
    "        for group in self.param_groups:\n",
    "            rho = group['rho']\n",
    "            # compute gradient as a long vector\n",
    "            g = torch.cat([p.grad.view(-1) for p in group['params']])\n",
    "            # calculate the search direction by Nystrom sketch and solve\n",
    "            UTg = torch.mv(self.nysh.U.t(), g) \n",
    "            g_new = torch.mv(self.nysh.U, (self.nysh.S + rho).reciprocal() * UTg) + g / rho - torch.mv(self.nysh.U, UTg) / rho            \n",
    "            self.inner_product.append(torch.dot(g, g_new))\n",
    "            shaped_gradient = []\n",
    "            ls = 0\n",
    "            for p in group['params']:\n",
    "                gp = g_new[ls:ls+torch.numel(p)].view(p.shape)\n",
    "                ls += torch.numel(p)\n",
    "                shaped_gradient.append(gp)\n",
    "            self.directions.append(shaped_gradient)\n",
    "            \n",
    "    def step(self, lr):\n",
    "        # one step update\n",
    "        group_id = 0\n",
    "        for group in self.param_groups:\n",
    "            direction = self.directions[group_id]\n",
    "            group_id += 1\n",
    "            ls = 0\n",
    "            # update model parameters\n",
    "            for p in group['params']:\n",
    "                gp = direction[ls]\n",
    "                ls += 1\n",
    "                p.data.add_(-lr * gp)\n",
    "                \n",
    "    def stepback(self, lr):\n",
    "        # one step update_back\n",
    "        group_id = 0\n",
    "        for group in self.param_groups:\n",
    "            direction = self.directions[group_id]\n",
    "            group_id += 1\n",
    "            ls = 0\n",
    "            # update model parameters\n",
    "            for p in group['params']:\n",
    "                gp = direction[ls]\n",
    "                ls += 1\n",
    "                p.data.add_(lr * gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcde8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassification()\n",
    "model.load_state_dict(torch.load(\"/data/sz533/nysnewton/initialmodel.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = NysHessianOpt(model.parameters(), lr = 0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b34461d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(optimizer.param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d4d9338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-3030989fd95c>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.S = torch.max(torch.square(S) - torch.tensor(shift), torch.tensor(0.0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020: | Loss: 0.26268 | Acc: 89.353\n",
      "Epoch 040: | Loss: 0.05880 | Acc: 97.647\n",
      "Epoch 060: | Loss: 0.27591 | Acc: 88.446\n",
      "Epoch 080: | Loss: 0.15070 | Acc: 94.436\n",
      "Epoch 100: | Loss: 0.18268 | Acc: 92.598\n"
     ]
    }
   ],
   "source": [
    "hes_interval = 300\n",
    "# update Hessian and Nystrom sketch every couple of steps\n",
    "line_search_interval = 1\n",
    "\n",
    "model = BinaryClassification()\n",
    "model.load_state_dict(torch.load(\"/data/sz533/nysnewton/initialmodel.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = NysHessianOptlinesearch(model.parameters())\n",
    "\n",
    "hes_iter = 0\n",
    "line_search_iter = 0\n",
    "\n",
    "alpha_max = 0.05\n",
    "alpha_min = 0.0005\n",
    "tau = 0.5\n",
    "beta = 0.1\n",
    "\n",
    "timelist1 = []\n",
    "losslist1 = []\n",
    "acclist1 = []\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "\n",
    "        if hes_iter % hes_interval == 0:\n",
    "            # update Hessian and sketch\n",
    "            optimizer.nysh.update_Hessian(X_batch, y_batch, model, criterion, device)\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.compute_direction()\n",
    "        \n",
    "        if line_search_iter % line_search_interval == 0:\n",
    "            alpha = alpha_max\n",
    "            optimizer.step(torch.tensor(alpha))\n",
    "            y_pred = model(X_batch)\n",
    "            update_loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "            # print('loss', loss.item())\n",
    "            # print('update loss', update_loss.item())\n",
    "            while update_loss.item() > loss.item() + alpha * beta * optimizer.inner_product[0].item() and alpha > alpha_min:\n",
    "                optimizer.stepback(torch.tensor(alpha))\n",
    "                alpha = tau * alpha\n",
    "                optimizer.step(torch.tensor(alpha))\n",
    "                y_pred = model(X_batch)\n",
    "                update_loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        else:\n",
    "            optimizer.step(torch.tensor(alpha))\n",
    "            # if alpha != max_rate:\n",
    "               # print('no line search', alpha, \"\\n\")\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        hes_iter += 1\n",
    "        line_search_iter += 1\n",
    "        epoch_time = timeit.default_timer()\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "    losslist1.append(epoch_loss/len(train_loader))\n",
    "    timelist1.append(epoch_time - start_time)\n",
    "    acclist1.append(epoch_acc/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "477ab5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-3030989fd95c>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.S = torch.max(torch.square(S) - torch.tensor(shift), torch.tensor(0.0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020: | Loss: 0.34757 | Acc: 86.078\n",
      "Epoch 040: | Loss: 0.18647 | Acc: 93.328\n",
      "Epoch 060: | Loss: 0.05034 | Acc: 99.074\n",
      "Epoch 080: | Loss: 0.01274 | Acc: 99.961\n",
      "Epoch 100: | Loss: 0.00533 | Acc: 100.000\n"
     ]
    }
   ],
   "source": [
    "hes_interval = 300\n",
    "# update Hessian and Nystrom sketch every couple of steps\n",
    "\n",
    "model = BinaryClassification()\n",
    "model.load_state_dict(torch.load(\"/data/sz533/nysnewton/initialmodel.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = NysHessianOpt(model.parameters())\n",
    "\n",
    "hes_iter = 0\n",
    "\n",
    "timelist2 = []\n",
    "losslist2 = []\n",
    "acclist2 = []\n",
    "\n",
    "lr = torch.tensor(0.003)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "\n",
    "        if hes_iter % hes_interval == 0:\n",
    "            # update Hessian and sketch\n",
    "            optimizer.nysh.update_Hessian(X_batch, y_batch, model, criterion, device)\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step(lr)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        hes_iter += 1\n",
    "        epoch_time = timeit.default_timer()\n",
    "\n",
    "    \n",
    "    if e % 20 == 0:\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "    losslist2.append(epoch_loss/len(train_loader))\n",
    "    timelist2.append(epoch_time - start_time)\n",
    "    acclist2.append(epoch_acc/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "728ac8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-3030989fd95c>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.S = torch.max(torch.square(S) - torch.tensor(shift), torch.tensor(0.0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020: | Loss: 0.18435 | Acc: 93.074\n",
      "Epoch 040: | Loss: 0.04531 | Acc: 99.132\n",
      "Epoch 060: | Loss: 0.01781 | Acc: 99.887\n",
      "Epoch 080: | Loss: 0.01046 | Acc: 99.990\n",
      "Epoch 100: | Loss: 0.00773 | Acc: 100.000\n"
     ]
    }
   ],
   "source": [
    "# decreasing step size\n",
    "\n",
    "hes_interval = 300\n",
    "# update Hessian and Nystrom sketch every couple of steps\n",
    "\n",
    "model = BinaryClassification()\n",
    "model.load_state_dict(torch.load(\"/data/sz533/nysnewton/initialmodel.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = NysHessianOpt(model.parameters())\n",
    "\n",
    "hes_iter = 0\n",
    "\n",
    "timelist3 = []\n",
    "losslist3 = []\n",
    "acclist3 = []\n",
    "\n",
    "initial_lr = torch.tensor(0.1)\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "\n",
    "        if hes_iter % hes_interval == 0:\n",
    "            # update Hessian and sketch\n",
    "            optimizer.nysh.update_Hessian(X_batch, y_batch, model, criterion, device)\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        lr = initial_lr / e\n",
    "        lr = torch.max(lr, torch.tensor(0.001))\n",
    "        \n",
    "        optimizer.step(lr)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        hes_iter += 1\n",
    "        epoch_time = timeit.default_timer()\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    \n",
    "    losslist3.append(epoch_loss/len(train_loader))\n",
    "    timelist3.append(epoch_time - start_time)\n",
    "    acclist3.append(epoch_acc/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a641db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "61391bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NysHessianOptlinesearchdouble(Optimizer):\n",
    "\n",
    "    def __init__(self, params, rank = 100, rho = 0.5):\n",
    "        # initialize the optimizer    \n",
    "        defaults = dict(rank = rank, rho = rho)\n",
    "        self.nysh = NysHessianpartial(rank, rho)\n",
    "        super(NysHessianOptlinesearchdouble, self).__init__(params, defaults)\n",
    "    \n",
    "    def compute_direction(self):\n",
    "        self.directions = []\n",
    "        self.expanddirections = []\n",
    "        self.inner_product = []\n",
    "        for group in self.param_groups:\n",
    "            rho = group['rho']\n",
    "            # compute gradient as a long vector\n",
    "            g = torch.cat([p.grad.view(-1) for p in group['params']])\n",
    "            # calculate the search direction by Nystrom sketch and solve\n",
    "            UTg = torch.mv(self.nysh.U.t(), g) \n",
    "            g_new = torch.mv(self.nysh.U, (self.nysh.S + rho).reciprocal() * UTg) + g / rho - torch.mv(self.nysh.U, UTg) / rho            \n",
    "            self.inner_product.append(torch.dot(g, g_new))\n",
    "            self.expanddirections.append(g_new)\n",
    "            shaped_gradient = []\n",
    "            ls = 0\n",
    "            for p in group['params']:\n",
    "                gp = g_new[ls:ls+torch.numel(p)].view(p.shape)\n",
    "                ls += torch.numel(p)\n",
    "                shaped_gradient.append(gp)\n",
    "            self.directions.append(shaped_gradient)       \n",
    "            \n",
    "    def step(self, lr):\n",
    "        # one step update\n",
    "        group_id = 0\n",
    "        for group in self.param_groups:\n",
    "            direction = self.directions[group_id]\n",
    "            group_id += 1\n",
    "            ls = 0\n",
    "            # update model parameters\n",
    "            for p in group['params']:\n",
    "                gp = direction[ls]\n",
    "                ls += 1\n",
    "                p.data.add_(-lr * gp)\n",
    "                \n",
    "    def stepback(self, lr):\n",
    "        # one step update_back\n",
    "        group_id = 0\n",
    "        for group in self.param_groups:\n",
    "            direction = self.directions[group_id]\n",
    "            group_id += 1\n",
    "            ls = 0\n",
    "            # update model parameters\n",
    "            for p in group['params']:\n",
    "                gp = direction[ls]\n",
    "                ls += 1\n",
    "                p.data.add_(lr * gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "76da7b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-3030989fd95c>:86: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.S = torch.max(torch.square(S) - torch.tensor(shift), torch.tensor(0.0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.49016 | Acc: 81.000\n",
      "Epoch 002: | Loss: 0.43427 | Acc: 83.559\n",
      "Epoch 003: | Loss: 0.41157 | Acc: 84.088\n",
      "Epoch 004: | Loss: 0.39773 | Acc: 84.417\n",
      "Epoch 005: | Loss: 0.38728 | Acc: 84.735\n",
      "Epoch 006: | Loss: 0.38201 | Acc: 84.917\n",
      "Epoch 007: | Loss: 0.37309 | Acc: 85.054\n",
      "Epoch 008: | Loss: 0.36870 | Acc: 85.270\n",
      "Epoch 009: | Loss: 0.35767 | Acc: 85.750\n",
      "Epoch 010: | Loss: 0.34943 | Acc: 86.054\n",
      "Epoch 011: | Loss: 0.34154 | Acc: 86.167\n",
      "Epoch 012: | Loss: 0.33275 | Acc: 86.324\n",
      "Epoch 013: | Loss: 0.33229 | Acc: 86.583\n",
      "Epoch 014: | Loss: 0.32925 | Acc: 86.593\n",
      "Epoch 015: | Loss: 0.31700 | Acc: 87.147\n",
      "Epoch 016: | Loss: 0.30888 | Acc: 87.412\n",
      "Epoch 017: | Loss: 0.30252 | Acc: 87.868\n",
      "Epoch 018: | Loss: 0.29698 | Acc: 88.083\n",
      "Epoch 019: | Loss: 0.28739 | Acc: 88.358\n",
      "Epoch 020: | Loss: 0.28367 | Acc: 88.554\n",
      "Epoch 021: | Loss: 0.27439 | Acc: 89.083\n",
      "Epoch 022: | Loss: 0.26995 | Acc: 89.358\n",
      "Epoch 023: | Loss: 0.26520 | Acc: 89.299\n",
      "Epoch 024: | Loss: 0.25765 | Acc: 89.480\n",
      "Epoch 025: | Loss: 0.25153 | Acc: 90.093\n",
      "Epoch 026: | Loss: 0.24791 | Acc: 90.221\n",
      "Epoch 027: | Loss: 0.23764 | Acc: 90.740\n",
      "Epoch 028: | Loss: 0.22132 | Acc: 91.554\n",
      "Epoch 029: | Loss: 0.21587 | Acc: 91.804\n",
      "Epoch 030: | Loss: 0.20971 | Acc: 91.838\n",
      "Epoch 031: | Loss: 0.20209 | Acc: 92.284\n",
      "Epoch 032: | Loss: 0.20038 | Acc: 92.510\n",
      "Epoch 033: | Loss: 0.21458 | Acc: 91.706\n",
      "Epoch 034: | Loss: 0.19223 | Acc: 92.588\n",
      "Epoch 035: | Loss: 0.17968 | Acc: 93.167\n",
      "Epoch 036: | Loss: 0.17519 | Acc: 93.221\n",
      "Epoch 037: | Loss: 0.17854 | Acc: 93.157\n",
      "Epoch 038: | Loss: 0.16630 | Acc: 93.681\n",
      "Epoch 039: | Loss: 0.15806 | Acc: 93.922\n",
      "Epoch 040: | Loss: 0.15810 | Acc: 93.853\n",
      "Epoch 041: | Loss: 0.15178 | Acc: 94.206\n",
      "Epoch 042: | Loss: 0.16348 | Acc: 93.819\n",
      "Epoch 043: | Loss: 0.13653 | Acc: 94.887\n",
      "Epoch 044: | Loss: 0.13128 | Acc: 95.025\n",
      "Epoch 045: | Loss: 0.13525 | Acc: 95.025\n",
      "Epoch 046: | Loss: 0.12057 | Acc: 95.574\n",
      "Epoch 047: | Loss: 0.10861 | Acc: 96.020\n",
      "Epoch 048: | Loss: 0.10620 | Acc: 96.157\n",
      "Epoch 049: | Loss: 0.10503 | Acc: 96.211\n",
      "Epoch 050: | Loss: 0.10692 | Acc: 95.838\n",
      "Epoch 051: | Loss: 0.11283 | Acc: 95.549\n",
      "Epoch 052: | Loss: 0.12065 | Acc: 95.534\n",
      "Epoch 053: | Loss: 0.09063 | Acc: 96.603\n",
      "Epoch 054: | Loss: 0.08031 | Acc: 96.966\n",
      "Epoch 055: | Loss: 0.08160 | Acc: 96.936\n",
      "Epoch 056: | Loss: 0.08705 | Acc: 96.652\n",
      "Epoch 057: | Loss: 0.09992 | Acc: 96.108\n",
      "Epoch 058: | Loss: 0.08769 | Acc: 96.711\n",
      "Epoch 059: | Loss: 0.07323 | Acc: 97.284\n",
      "Epoch 060: | Loss: 0.06037 | Acc: 97.691\n",
      "Epoch 061: | Loss: 0.05454 | Acc: 98.137\n",
      "Epoch 062: | Loss: 0.06463 | Acc: 97.412\n",
      "Epoch 063: | Loss: 0.06134 | Acc: 97.779\n",
      "Epoch 064: | Loss: 0.04423 | Acc: 98.436\n",
      "Epoch 065: | Loss: 0.04383 | Acc: 98.402\n",
      "Epoch 066: | Loss: 0.03509 | Acc: 98.691\n",
      "Epoch 067: | Loss: 0.03116 | Acc: 98.897\n",
      "Epoch 068: | Loss: 0.03122 | Acc: 98.863\n",
      "Epoch 069: | Loss: 0.02655 | Acc: 99.118\n",
      "Epoch 070: | Loss: 0.03591 | Acc: 98.603\n",
      "Epoch 071: | Loss: 0.03076 | Acc: 98.951\n",
      "Epoch 072: | Loss: 0.03029 | Acc: 98.819\n",
      "Epoch 073: | Loss: 0.02675 | Acc: 99.093\n",
      "Epoch 074: | Loss: 0.02500 | Acc: 99.230\n",
      "Epoch 075: | Loss: 0.02491 | Acc: 99.069\n",
      "Epoch 076: | Loss: 0.01961 | Acc: 99.363\n",
      "Epoch 077: | Loss: 0.01718 | Acc: 99.422\n",
      "Epoch 078: | Loss: 0.01454 | Acc: 99.574\n",
      "Epoch 079: | Loss: 0.01720 | Acc: 99.471\n",
      "Epoch 080: | Loss: 0.01255 | Acc: 99.603\n",
      "Epoch 081: | Loss: 0.02781 | Acc: 99.010\n",
      "Epoch 082: | Loss: 0.01653 | Acc: 99.422\n",
      "Epoch 083: | Loss: 0.01474 | Acc: 99.490\n",
      "Epoch 084: | Loss: 0.01692 | Acc: 99.441\n",
      "Epoch 085: | Loss: 0.01229 | Acc: 99.588\n",
      "Epoch 086: | Loss: 0.01411 | Acc: 99.471\n",
      "Epoch 087: | Loss: 0.00874 | Acc: 99.770\n",
      "Epoch 088: | Loss: 0.00913 | Acc: 99.730\n",
      "Epoch 089: | Loss: 0.00695 | Acc: 99.838\n",
      "Epoch 090: | Loss: 0.00712 | Acc: 99.784\n",
      "Epoch 091: | Loss: 0.00691 | Acc: 99.838\n",
      "Epoch 092: | Loss: 0.00721 | Acc: 99.833\n",
      "Epoch 093: | Loss: 0.00667 | Acc: 99.804\n",
      "Epoch 094: | Loss: 0.00582 | Acc: 99.892\n",
      "Epoch 095: | Loss: 0.00470 | Acc: 99.882\n",
      "Epoch 096: | Loss: 0.00563 | Acc: 99.843\n",
      "Epoch 097: | Loss: 0.00573 | Acc: 99.814\n",
      "Epoch 098: | Loss: 0.00490 | Acc: 99.897\n",
      "Epoch 099: | Loss: 0.00529 | Acc: 99.853\n",
      "Epoch 100: | Loss: 0.00500 | Acc: 99.843\n"
     ]
    }
   ],
   "source": [
    "hes_interval = 300\n",
    "# update Hessian and Nystrom sketch every couple of steps\n",
    "line_search_interval = 1\n",
    "\n",
    "model = BinaryClassification()\n",
    "model.load_state_dict(torch.load(\"/data/sz533/nysnewton/initialmodel.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "optimizer = NysHessianOptlinesearchdouble(model.parameters())\n",
    "\n",
    "hes_iter = 0\n",
    "line_search_iter = 0\n",
    "\n",
    "alpha_max = 0.05\n",
    "alpha_min = 0.001\n",
    "tau = 0.5\n",
    "beta = 0.01\n",
    "\n",
    "timelist4 = []\n",
    "losslist4 = []\n",
    "acclist4 = []\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "model.train()\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    train_loader_iter = iter(train_loader)\n",
    "    \n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_loader_iter):\n",
    "\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        X_batch_2, y_batch_2 = next(train_loader_iter)\n",
    "        X_batch_2, y_batch_2 = X_batch_2.to(device), y_batch_2.to(device)\n",
    "        \n",
    "        # doing with first batch\n",
    "        if hes_iter % hes_interval == 0:\n",
    "            # update Hessian and sketch\n",
    "            optimizer.nysh.update_Hessian(X_batch, y_batch, model, criterion, device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.compute_direction()\n",
    "        \n",
    "        if line_search_iter % line_search_interval == 0:\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            y_pred_second = model(X_batch_2)\n",
    "            loss_second = criterion(y_pred_second, y_batch_2.unsqueeze(1))\n",
    "            loss_second.backward()\n",
    "            loss_second_prev = loss_second.item()\n",
    "            \n",
    "            grads_second = []\n",
    "            for param in model.parameters():\n",
    "                if not param.requires_grad:\n",
    "                    continue\n",
    "                grads_second.append(0. if param.grad is None else param.grad + 0.)\n",
    "            \n",
    "            grads_second_expand = torch.cat([p.view(-1) for p in grads_second])\n",
    "            inner_second = torch.dot(grads_second_expand, optimizer.expanddirections[0]).item()\n",
    "            \n",
    "            alpha = alpha_max\n",
    "            optimizer.step(torch.tensor(alpha))\n",
    "            y_pred_first = model(X_batch)\n",
    "            loss_first = criterion(y_pred_first, y_batch.unsqueeze(1))\n",
    "            y_pred_second = model(X_batch_2)\n",
    "            loss_second_post = criterion(y_pred_second, y_batch_2.unsqueeze(1))\n",
    "            \n",
    "            while (loss_first.item() > loss.item() + alpha * beta * optimizer.inner_product[0].item() or \\\n",
    "            loss_second_post.item() > loss_second_prev + alpha * beta * inner_second) and \\\n",
    "            alpha > alpha_min:\n",
    "                \n",
    "                optimizer.stepback(torch.tensor(alpha))\n",
    "                alpha = tau * alpha\n",
    "                optimizer.step(torch.tensor(alpha))\n",
    "                y_pred_first = model(X_batch)\n",
    "                loss_first = criterion(y_pred_first, y_batch.unsqueeze(1))\n",
    "                y_pred_second = model(X_batch_2)\n",
    "                loss_second_post = criterion(y_pred_second, y_batch_2.unsqueeze(1))\n",
    "            # print('alpha1', alpha)\n",
    "        else:\n",
    "            optimizer.step(torch.tensor(alpha))\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        hes_iter += 1\n",
    "        line_search_iter += 1\n",
    "        epoch_time = timeit.default_timer()\n",
    "        \n",
    "        # doing with second batch\n",
    "        \n",
    "        if hes_iter % hes_interval == 0:\n",
    "            # update Hessian and sketch\n",
    "            optimizer.nysh.update_Hessian(X_batch_2, y_batch_2, model, criterion, device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred_2 = model(X_batch_2)\n",
    "\n",
    "        loss = criterion(y_pred_2, y_batch_2.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred_2, y_batch_2.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.compute_direction()\n",
    "        \n",
    "        if line_search_iter % line_search_interval == 0:\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            y_pred_second = model(X_batch)\n",
    "            loss_second = criterion(y_pred_second, y_batch.unsqueeze(1))\n",
    "            loss_second.backward()\n",
    "            loss_second_prev = loss_second.item()\n",
    "            \n",
    "            grads_second = []\n",
    "            for param in model.parameters():\n",
    "                if not param.requires_grad:\n",
    "                    continue\n",
    "                grads_second.append(0. if param.grad is None else param.grad + 0.)\n",
    "            \n",
    "            grads_second_expand = torch.cat([p.view(-1) for p in grads_second])\n",
    "            inner_second = torch.dot(grads_second_expand, optimizer.expanddirections[0]).item()\n",
    "            \n",
    "            alpha = alpha_max\n",
    "            optimizer.step(torch.tensor(alpha))\n",
    "            y_pred_first = model(X_batch_2)\n",
    "            loss_first = criterion(y_pred_first, y_batch_2.unsqueeze(1))\n",
    "            y_pred_second = model(X_batch)\n",
    "            loss_second_post = criterion(y_pred_second, y_batch.unsqueeze(1))\n",
    "            \n",
    "            while (loss_first.item() > loss.item() + alpha * beta * optimizer.inner_product[0].item() or \\\n",
    "            loss_second_post.item() > loss_second_prev + alpha * beta * inner_second) and \\\n",
    "            alpha > alpha_min:\n",
    "    \n",
    "                optimizer.stepback(torch.tensor(alpha))\n",
    "                alpha = tau * alpha\n",
    "                optimizer.step(torch.tensor(alpha))\n",
    "                y_pred_first = model(X_batch_2)\n",
    "                loss_first = criterion(y_pred_first, y_batch_2.unsqueeze(1))\n",
    "                y_pred_second = model(X_batch)\n",
    "                loss_second_post = criterion(y_pred_second, y_batch.unsqueeze(1))\n",
    "            # print('alpha2', alpha)\n",
    "        else:\n",
    "            optimizer.step(torch.tensor(alpha))\n",
    "\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        hes_iter += 1\n",
    "        line_search_iter += 1\n",
    "        epoch_time = timeit.default_timer()\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}')\n",
    "    losslist4.append(epoch_loss/len(train_loader))\n",
    "    timelist4.append(epoch_time - start_time)\n",
    "    acclist4.append(epoch_acc/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "72bf04a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(timelist1, losslist1, 'r--', timelist2, losslist2, 'b--', timelist3, losslist3, 'g--', timelist4, losslist4, 'm--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09463c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34121f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualsz5332",
   "language": "python",
   "name": "virtualsz5332"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
